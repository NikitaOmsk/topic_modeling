{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "\n",
    "### Функция для чтения датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fpath):\n",
    "    data = []\n",
    "    with open(fpath, 'r') as f:\n",
    "        for line in f:\n",
    "            ex = {}\n",
    "            for subline in line[1:-2].replace('\"', '').split(', '):\n",
    "                key, value = subline.split(': ')\n",
    "                try:\n",
    "                    ex[key] = int(value)\n",
    "                except Exception:\n",
    "                    ex[key] = value\n",
    "            data.append(ex)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коллекции уже представлен обработанный датасет. Произведена лемматизация, удалены стоп-слова и знаки препинания. Поэтому попробуем использовать уже подготовленные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data('imdb/lemmatized_wo_stopwords/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сразу посмотрим на то, как связаны label и score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0., 5100.],\n",
       "       [   0., 2284.],\n",
       "       [   0., 2420.],\n",
       "       [   0., 2696.],\n",
       "       [   0.,    0.],\n",
       "       [   0.,    0.],\n",
       "       [2496.,    0.],\n",
       "       [3009.,    0.],\n",
       "       [2263.,    0.],\n",
       "       [4732.,    0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_twos = np.zeros((10, 2))\n",
    "for s in train_data:\n",
    "    i = s['score'] - 1\n",
    "    j = s['label'] - 1\n",
    "    ones_twos[i, j] += 1\n",
    "ones_twos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что score 5 и 6 отсутствует, высоким оценкам (7-10) соответствует label 1, а низким (1-4) - 2.\n",
    "Поэтому задача определения score автоматически решает задачу определения label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на данные --- количество, среднюю и минимальную длину текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of samples: 25000\n",
      "Mean length: 117.6394\n",
      "Std: 88.88958098472509\n",
      "Minimum: 3\n",
      "10%: 45\n",
      "25%: 62\n",
      "50%: 87\n",
      "75%: 143\n",
      "90%: 233\n",
      "Maximum: 1416\n"
     ]
    }
   ],
   "source": [
    "count_data = len(train_data)\n",
    "data_length = sorted([len(sample['text'].split()) for sample in train_data])\n",
    "print('Count of samples: {}\\nMean length: {}\\nStd: {}\\nMinimum: {}\\n10%: {}\\n25%: {}\\n50%: {}\\n'\n",
    "      '75%: {}\\n90%: {}\\nMaximum: {}'.format(count_data, np.mean(data_length), np.std(data_length), \n",
    "                                             data_length[0], data_length[count_data//10], \n",
    "                                             data_length[count_data//4], data_length[count_data//2], \n",
    "                                             data_length[count_data * 3//4], data_length[count_data * 9//10], \n",
    "                                             data_length[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что разброс в данных большой. Вспоминая специфику данных -- отзывы к фильмам -- понимаем, что большинство пользователей пишут коротко, и лишь некоторые растекаются мысью по древу.\n",
    "Во всяком случае, это не твиттер с 30-40 словами, поэтому можно ожидать приемлемых результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для перевода данных в формат BigARTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data_for_bigartm(data, bigartm_data_path):\n",
    "    with open(bigartm_data_path, 'w') as f:\n",
    "        for i, sample in enumerate(data):\n",
    "            f.write('review_{} {} |@score {}\\n'.format(i, sample['text'], sample['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data_for_bigartm(data, bigartm_data_path):\n",
    "    with open(bigartm_data_path, 'w') as f:\n",
    "        for i, sample in enumerate(data):\n",
    "            f.write('review_{} {}\\n'.format(i, sample['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(train_data, test_size=0.2)\n",
    "prepare_train_data_for_bigartm(train_set, 'train.txt')\n",
    "prepare_test_data_for_bigartm(val_set, 'val.txt')\n",
    "train_scores = [x['score'] for x in train_set]\n",
    "val_scores = [x['score'] for x in val_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построим модель BigARTM\n",
    "\n",
    "### Сначала определим vectorizer и сохраним словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.2\n"
     ]
    }
   ],
   "source": [
    "import artm\n",
    "import pyLDAvis\n",
    "\n",
    "artm.ARTM(num_topics=1)\n",
    "print(artm.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "bv_train = artm.BatchVectorizer(data_path='train.txt', data_format='vowpal_wabbit', \n",
    "                                batch_size=10000, target_folder='train_batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "bv_val = artm.BatchVectorizer(data_path='val.txt', data_format='vowpal_wabbit', \n",
    "                              batch_size=10000, target_folder='val_batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "dictionary = artm.Dictionary()\n",
    "dictionary.gather(data_path='train_batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализируем модель и добавим метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "model = artm.ARTM(num_topics=100, dictionary=dictionary, class_ids={'@default_class': 1.0, '@score': 5.0})\n",
    "\n",
    "model.scores.add(artm.TopTokensScore(name='top-tokens', num_tokens=15))\n",
    "model.scores.add(artm.SparsityPhiScore(name='sparsity', class_id='@score'))\n",
    "model.scores.add(artm.PerplexityScore(name='perplexity', dictionary=dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В качестве первой попытки обучим модель без регуляризаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: sparsity = 0.0, perplexity = 469034.9375\n",
      "Iteration 1: sparsity = 0.0, perplexity = 16994.94140625\n",
      "Iteration 2: sparsity = 0.0, perplexity = 10372.28125\n",
      "Iteration 3: sparsity = 0.0, perplexity = 6829.06591796875\n",
      "Iteration 4: sparsity = 0.0, perplexity = 5521.0244140625\n",
      "Iteration 5: sparsity = 0.0, perplexity = 5013.30810546875\n",
      "Iteration 6: sparsity = 0.0, perplexity = 4791.04833984375\n",
      "Iteration 7: sparsity = 0.0, perplexity = 4684.14111328125\n",
      "Iteration 8: sparsity = 0.0, perplexity = 4634.48046875\n",
      "Iteration 9: sparsity = 0.0, perplexity = 4618.26806640625\n",
      "Iteration 10: sparsity = 0.0012499999720603228, perplexity = 4622.0087890625\n",
      "Iteration 11: sparsity = 0.0062500000931322575, perplexity = 4637.11865234375\n",
      "Iteration 12: sparsity = 0.013749999925494194, perplexity = 4657.953125\n",
      "Iteration 13: sparsity = 0.028750000521540642, perplexity = 4680.97509765625\n",
      "Iteration 14: sparsity = 0.04625000059604645, perplexity = 4704.58056640625\n",
      "Iteration 15: sparsity = 0.057500001043081284, perplexity = 4728.1064453125\n",
      "Iteration 16: sparsity = 0.07374999672174454, perplexity = 4751.115234375\n",
      "Iteration 17: sparsity = 0.10000000149011612, perplexity = 4772.9765625\n",
      "Iteration 18: sparsity = 0.11124999821186066, perplexity = 4793.24365234375\n",
      "Iteration 19: sparsity = 0.13625000417232513, perplexity = 4812.029296875\n",
      "Iteration 20: sparsity = 0.1574999988079071, perplexity = 4830.08349609375\n",
      "Iteration 21: sparsity = 0.17499999701976776, perplexity = 4847.4169921875\n",
      "Iteration 22: sparsity = 0.19750000536441803, perplexity = 4863.85888671875\n",
      "Iteration 23: sparsity = 0.22624999284744263, perplexity = 4879.72119140625\n",
      "Iteration 24: sparsity = 0.2524999976158142, perplexity = 4895.34228515625\n",
      "Iteration 25: sparsity = 0.2737500071525574, perplexity = 4910.30810546875\n",
      "Iteration 26: sparsity = 0.30000001192092896, perplexity = 4924.33837890625\n",
      "Iteration 27: sparsity = 0.3199999928474426, perplexity = 4937.73974609375\n",
      "Iteration 28: sparsity = 0.33375000953674316, perplexity = 4950.63525390625\n",
      "Iteration 29: sparsity = 0.3425000011920929, perplexity = 4963.14697265625\n",
      "Iteration 30: sparsity = 0.3712500035762787, perplexity = 4975.12890625\n",
      "Iteration 31: sparsity = 0.38374999165534973, perplexity = 4986.9228515625\n",
      "Iteration 32: sparsity = 0.4025000035762787, perplexity = 4998.5341796875\n",
      "Iteration 33: sparsity = 0.41624999046325684, perplexity = 5009.92236328125\n",
      "Iteration 34: sparsity = 0.4375, perplexity = 5021.18896484375\n",
      "Iteration 35: sparsity = 0.4449999928474426, perplexity = 5032.42138671875\n",
      "Iteration 36: sparsity = 0.45249998569488525, perplexity = 5043.33447265625\n",
      "Iteration 37: sparsity = 0.4662500023841858, perplexity = 5053.8349609375\n",
      "Iteration 38: sparsity = 0.47999998927116394, perplexity = 5063.75927734375\n",
      "Iteration 39: sparsity = 0.4925000071525574, perplexity = 5073.1064453125\n",
      "Iteration 40: sparsity = 0.5024999976158142, perplexity = 5082.0263671875\n",
      "Iteration 41: sparsity = 0.5049999952316284, perplexity = 5090.640625\n",
      "Iteration 42: sparsity = 0.5149999856948853, perplexity = 5099.05126953125\n",
      "Iteration 43: sparsity = 0.5287500023841858, perplexity = 5107.32470703125\n",
      "Iteration 44: sparsity = 0.5375000238418579, perplexity = 5115.49658203125\n",
      "Iteration 45: sparsity = 0.5425000190734863, perplexity = 5123.5869140625\n",
      "Iteration 46: sparsity = 0.5525000095367432, perplexity = 5131.45361328125\n",
      "Iteration 47: sparsity = 0.5625, perplexity = 5139.14404296875\n",
      "Iteration 48: sparsity = 0.5674999952316284, perplexity = 5146.64794921875\n",
      "Iteration 49: sparsity = 0.5762500166893005, perplexity = 5153.8515625\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    model.fit_offline(bv_train, num_collection_passes=1)\n",
    "    print('Iteration {}: sparsity = {}, perplexity = {}'.format(\\\n",
    "        i, model.score_tracker['sparsity'].value[-1], model.score_tracker['perplexity'].value[-1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что с 10 итерации перплексия начинает расти -- эффект переобучения. Это плохо, надо использовать регуляризаторы. Чтобы не копировать постоянно код, напишем функцию, создающую и обучающую модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция для создания и обучения модели с регуляризаторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def create_and_fit_model_with_regularizers(bv_train, num_topics, epochs, \n",
    "                                           tau_def, tau_score, score_idx, verbose=1):\n",
    "    model = artm.ARTM(num_topics=num_topics, dictionary=dictionary, \n",
    "                      class_ids={'@default_class': 1.0, '@score': score_idx})\n",
    "    model.scores.add(artm.TopTokensScore(name='top-tokens', num_tokens=15))\n",
    "    model.scores.add(artm.SparsityPhiScore(name='sparsity', class_id='@score'))\n",
    "    model.scores.add(artm.PerplexityScore(name='perplexity', dictionary=dictionary))\n",
    "    \n",
    "    model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_default', \n",
    "                                                           tau=tau_def,\n",
    "                                                           class_ids=['@default_class']))\n",
    "    model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_score', \n",
    "                                                           tau=tau_score,\n",
    "                                                           class_ids=['@score']))\n",
    "    old_sparsity = -1\n",
    "    old_perplexity = -1\n",
    "    stop = 10\n",
    "    for i in range(epochs):\n",
    "        model.fit_offline(bv_train, num_collection_passes=1)\n",
    "        sparsity = model.score_tracker['sparsity'].value[-1]\n",
    "        perplexity = model.score_tracker['perplexity'].value[-1]\n",
    "        if verbose == 2:\n",
    "            print('Iteration {}: sparsity = {}, perplexity = {}'.format(i, sparsity, perplexity))\n",
    "        if sparsity < old_sparsity or sparsity == old_sparsity and perplexity > old_perplexity:\n",
    "            stop -= 1\n",
    "            if stop == 0:\n",
    "                break\n",
    "        else:\n",
    "            old_sparsity = sparsity\n",
    "            old_perplexity = perplexity\n",
    "    if verbose == 1:\n",
    "        print('Iteration last: sparsity = {}, perplexity = {}'.format(sparsity, perplexity))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция, которая для заданных параметров обучает модель и оценивает её на валидационных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_hyperparameters(bv_train, bv_val, scores_train, scores_val,\n",
    "                             num_topics, epochs, tau_def, tau_score, score_idx, verbose=1, save_model=False):\n",
    "    model = create_and_fit_model_with_regularizers(bv_train, num_topics, epochs, \n",
    "                                                   tau_def, tau_score, score_idx, verbose)\n",
    "    p_cd_val = model.transform(batch_vectorizer=bv_val, predict_class_id='@score').T\n",
    "    y_val_pred = [int(x) for x in p_cd_val.idxmax(axis=1).values]\n",
    "    f1_val = f1_score(scores_val, y_val_pred, average='macro')\n",
    "    acc_val = accuracy_score(scores_val, y_val_pred)\n",
    "    # print('Val: f1_macro = {}, accuracy = {}'.format(f1_val, acc_val))\n",
    "    p_cd_train = model.transform(batch_vectorizer=bv_train, predict_class_id='@score').T\n",
    "    y_train_pred = [int(x) for x in p_cd_train.idxmax(axis=1).values]\n",
    "    f1_train = f1_score(scores_train, y_train_pred, average='macro')\n",
    "    acc_train = accuracy_score(scores_train, y_train_pred)\n",
    "    # print('Train: f1_macro = {}, accuracy = {}'.format(f1_train, acc_train))\n",
    "    if save_model:\n",
    "        return {\n",
    "            'model': model,\n",
    "            'f1_val': f1_val,\n",
    "            'acc_val': acc_val,\n",
    "            'f1_train': f1_train,\n",
    "            'acc_train': acc_train\n",
    "        }\n",
    "    else:\n",
    "        del model\n",
    "        return {\n",
    "            'f1_val': f1_val,\n",
    "            'acc_val': acc_val,\n",
    "            'f1_train': f1_train,\n",
    "            'acc_train': acc_train\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration last: sparsity = 0.9762499928474426, perplexity = 6163.5693359375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': artm.ARTM(num_topics=100, num_tokens=71992, class_ids=['@default_class', '@score']),\n",
       " 'f1_val': 0.1559919903532782,\n",
       " 'acc_val': 0.1706,\n",
       " 'f1_train': 0.42828186109613126,\n",
       " 'acc_train': 0.44625}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_hyperparameters(bv_train, bv_val, train_scores, val_scores, 100, 30, 1e+6, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "del train_data\n",
    "del train_set\n",
    "del val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acer/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 100000.0 1 1\n",
      "Iteration last: sparsity = 0.05249999836087227, perplexity = 10421.568359375\n",
      "{'f1_val': 0.21434314258570103, 'acc_val': 0.3568, 'f1_train': 0.10434035542143785, 'acc_train': 0.17085}\n",
      "50 100000.0 1 2\n",
      "Iteration last: sparsity = 0.10750000178813934, perplexity = 9152.359375\n",
      "{'f1_val': 0.22220412176353266, 'acc_val': 0.3332, 'f1_train': 0.11867192260945503, 'acc_train': 0.16255}\n",
      "50 100000.0 1 5\n",
      "Iteration last: sparsity = 0.5575000047683716, perplexity = 6220.5546875\n",
      "{'f1_val': 0.24988371153878702, 'acc_val': 0.343, 'f1_train': 0.11994723293992603, 'acc_train': 0.14755}\n",
      "50 100000.0 1 10\n",
      "Iteration last: sparsity = 0.7799999713897705, perplexity = 4130.38232421875\n",
      "{'f1_val': 0.2300062325589405, 'acc_val': 0.3526, 'f1_train': 0.12146620870690021, 'acc_train': 0.14335}\n",
      "50 100000.0 5 1\n",
      "Iteration last: sparsity = 0.06750000268220901, perplexity = 10419.9501953125\n",
      "{'f1_val': 0.2160978169815948, 'acc_val': 0.3578, 'f1_train': 0.10465286911732574, 'acc_train': 0.17035}\n",
      "50 100000.0 5 2\n",
      "Iteration last: sparsity = 0.12250000238418579, perplexity = 9130.6943359375\n",
      "{'f1_val': 0.2224718815497288, 'acc_val': 0.3324, 'f1_train': 0.11880528154947254, 'acc_train': 0.16215}\n",
      "50 100000.0 5 5\n",
      "Iteration last: sparsity = 0.5674999952316284, perplexity = 6222.26904296875\n",
      "{'f1_val': 0.2517043584637537, 'acc_val': 0.3444, 'f1_train': 0.12007667197676163, 'acc_train': 0.1472}\n",
      "50 100000.0 5 10\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for num_topics in [50, 100, 200]:\n",
    "    for tau_def in [1e+5, 1e+6, 1e+7]:\n",
    "        for tau_score in [1, 5, 10, 20]:\n",
    "            for score_idx in [1, 2, 5, 10]:\n",
    "                key = '{} {} {} {}'.format(num_topics, tau_def, tau_score, score_idx)\n",
    "                print(key)\n",
    "                results[key] = evaluate_hyperparameters(bv_train, bv_val, train_scores, val_scores, \n",
    "                                                        num_topics, 50, tau_def, tau_score, score_idx)\n",
    "                print(results[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
